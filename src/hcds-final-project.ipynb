{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Final Project - Analysis of Census Income Data </center>\n",
    "\n",
    "## <center> Dane Jordan </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "- [Introduction](#Introduction)\n",
    "- [Background/Related Work](#Background/Related-Work)\n",
    "- [Methods](#Methods)\n",
    "  - [Getting the census income data](#Getting-the-census-income-data)\n",
    "  - [Data cleaning](#Data-cleaning)\n",
    "  - [Exploratory data analysis - EDA](#Exploratory-data-analysis---EDA)\n",
    "  - [Deal with missing values and encode categorical features](#Deal-with-missing-values-and-encode-categorical-features)\n",
    "  - [Modeling](#Modeling)\n",
    "    - [Split DataFrame into training and testing](#Split-DataFrame-into-training-and-testing)\n",
    "    - [Split into features/response, training/validation, and standardize/scale data](#Split-into-features/response,-training/validation,-and-standardize/scale-data)\n",
    "- [Findings](#Findings)\n",
    "  - [Visualize Pearson correlation confusion matrix among features](#Visualize-Pearson-correlation-confusion-matrix-among-features)\n",
    "  - [Fit logistic regression model with cross-validation and calculate accuracy](#Fit-logistic-regression-model-with-cross-validation-and-calculate-accuracy)\n",
    "  - [Visualize the coefficients](#Visualize-the-coefficients)\n",
    "- [Discussion/Implications](#Discussion/Implications)\n",
    "- [Conclusion](#blah)\n",
    "- [References](#References)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "[[back to Contents](#Contents)]\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background/Related Work\n",
    "[[back to Contents](#Contents)]\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "[[back to Contents](#Contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries that will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn off unnecessary warnings. When reassigning columns while changing categorical variables into numerical equivalents or boolean alternatives, pandas throws a warning for a `SettingWithCopyWarning`. This is unnecessary for our purposes and as such it has been turned off to not add confusion during this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# turn off warning for chained assignment (unnecessary for operation)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define functions that will be used throughout the analysis. To save ourselves from repetitive code use, we have implemented some functions. They are as follows:\n",
    "- `binarize_cat_vars` - encodes the categorical features as new features in a boolean format (extends the feature space significantly)\n",
    "- `corr_heatmap` - visualize Pearson correlation heatmap for a DataFrame\n",
    "- `data_prep` - separates the features and response, splits the data into a training and testing set, and standardizes/scales the feature data appropriately\n",
    "- `encode_cat_vars` - arbitrarily encodes the categorical features as numeric\n",
    "- `model_logistic` - trains a LogisticRegressionCV() model and returns accuracy scores against a validation set and a test set\n",
    "- `visualize_coefs` - plots a bar graph of the fitted model coefficients (sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize_cat_vars(df):\n",
    "    \n",
    "    '''\n",
    "    encodes the categorical features as new features in a boolean format (extends the feature space significantly)\n",
    "    :param df: DataFrame to be encoded\n",
    "    '''\n",
    "    \n",
    "    # assing the label binarizer and label encoder\n",
    "    lb = LabelBinarizer()\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # create list of labels\n",
    "    label_list = ['type_employer',\n",
    "                  'marital',\n",
    "                  'occupation',\n",
    "                  'relationship',\n",
    "                  'race',\n",
    "                  'country']\n",
    "    \n",
    "    binary_label_list = ['sex',\n",
    "                         'income']\n",
    "    \n",
    "    # change the categorical variables to features and associated binary indicator\n",
    "    for i in df[label_list]:\n",
    "        k = 0\n",
    "        for j in sorted(df[i].unique()):\n",
    "            df[str(i + '_' + j)] = lb.fit_transform(df[i])[:, k]\n",
    "            k += 1\n",
    "    \n",
    "    # change the categorical variables that are already binary to numerical\n",
    "    for i in binary_label_list:\n",
    "        df[i] = le.fit_transform(df[i])\n",
    "    \n",
    "    # drop columns that have been binarized\n",
    "    df = df.drop(label_list, axis=1)\n",
    "    \n",
    "    # return new df with categorical variables encoded as features\n",
    "    return df\n",
    "\n",
    "\n",
    "def corr_heatmap(df, title_prefix='', figsize=(12, 12), annot=True, cbar=False, threshold=0, label_size=25, tick_size=20):\n",
    "    \n",
    "    '''\n",
    "    visualize pearson correlation heatmap for a DataFrame\n",
    "    :param df: DataFrame\n",
    "    :param annot: boolean\n",
    "    '''\n",
    "    \n",
    "    df = np.round(df.corr(), decimals=2) + 0\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sns.heatmap(df[(df >= threshold) | (df <= -threshold)], center=0, annot=annot, fmt='.2g', annot_kws={'size': 16}, square=True, cbar=cbar)\n",
    "    sns.plt.title(str(title_prefix + 'Pearson Correlations'), fontsize=30)\n",
    "    sns.plt.xlabel('Features', fontsize=label_size)\n",
    "    sns.plt.xticks(fontsize=tick_size, rotation='vertical')\n",
    "    sns.plt.ylabel('Features', fontsize=label_size)\n",
    "    sns.plt.yticks(fontsize=tick_size, rotation='horizontal')\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "def data_prep(df, train_size=0.67):\n",
    "    \n",
    "    '''\n",
    "    separates the features and response, splits the data into a training and testing set,\n",
    "    and standardizes/scales the feature data appropriately\n",
    "    :param df: DataFrame containing feature/response data to be prepared\n",
    "    :param train_size: percentage of data split into the training set\n",
    "    '''\n",
    "\n",
    "    # separate the features from the response\n",
    "    df_features = df.drop(['income'], axis=1)\n",
    "    df_response = df['income']\n",
    "\n",
    "    # split the data into a training and testing set\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_features,\n",
    "                                                        df_response,\n",
    "                                                        train_size=train_size,\n",
    "                                                        random_state=6,\n",
    "                                                        stratify=df_response)\n",
    "\n",
    "    # assign the standard scaler\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # standardize and scale the data (not including the response variable, income)\n",
    "    x_train = scaler.fit_transform(x_train)\n",
    "    x_test = scaler.transform(x_test)\n",
    "    \n",
    "    # return training and testing sets with features and response separated\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def encode_cat_vars(df):\n",
    "\n",
    "    '''\n",
    "    arbitrarily encodes the categorical features as numeric\n",
    "    :param df: DataFrame to be encoded\n",
    "    '''\n",
    "    \n",
    "    # assign the label encoder\n",
    "    le = LabelEncoder()\n",
    "    \n",
    "    # create list of labels\n",
    "    label_list = ['type_employer',\n",
    "                  'marital',\n",
    "                  'occupation',\n",
    "                  'relationship',\n",
    "                  'race',\n",
    "                  'sex',\n",
    "                  'country',\n",
    "                  'income']\n",
    "\n",
    "    # change the categorical variables to an associated numerical label for ML\n",
    "    for i in label_list:\n",
    "        try:\n",
    "            df[i] = le.fit_transform(df[i])\n",
    "        except KeyError:\n",
    "            pass\n",
    "\n",
    "    # return new df with categorical variables encoded\n",
    "    return df\n",
    "\n",
    "\n",
    "def model_logistic(x_train, x_valid, x_test, y_train, y_valid, y_test):\n",
    "    \n",
    "    '''\n",
    "    trains a LogisticRegressionCV() model and returns accuracy scores against a validation and test set\n",
    "    :param x_train: DataFrame\n",
    "    :param x_valid: DataFrame\n",
    "    :param x_test: DataFrame\n",
    "    :param y_train: DataFrame\n",
    "    :param y_valid: DataFrame\n",
    "    :param y_test: DataFrame\n",
    "    '''\n",
    "    \n",
    "    clf_logCV = LogisticRegressionCV()\n",
    "    clf_logCV.fit(x_train, y_train)\n",
    "    \n",
    "    y_predict_valid = clf_logCV.predict(x_valid)\n",
    "    print('Validation Accuracy: %.2f' % (metrics.accuracy_score(y_predict_valid, y_valid)*100) + '%')\n",
    "    \n",
    "    y_predict_test = clf_logCV.predict(x_test)\n",
    "    print('Test Accuracy: %.2f' % (metrics.accuracy_score(y_predict_test, y_test)*100) + '%')\n",
    "    \n",
    "    return clf_logCV\n",
    "\n",
    "\n",
    "def visualize_coefs(model, df, title_prefix='', label_size=25, tick_size=25):\n",
    "    \n",
    "    '''\n",
    "    plots a bar graph of the fitted model coefficients (sorted)\n",
    "    :param model: fitted ML model\n",
    "    :param df: DataFrame associated with model\n",
    "    '''\n",
    "    \n",
    "    ax = pd.DataFrame({'coef': model.coef_[0], 'variable': df.columns[:-1]})\n",
    "    ax.sort_values('coef').plot(x='variable', y='coef', kind='bar', figsize=(16, 12), fontsize=20, legend=False)\n",
    "    plt.title(str(title_prefix + 'Logistic Regression Coefficients'), fontsize=30)\n",
    "    plt.xlabel('Features', fontsize=label_size)\n",
    "    plt.xticks(fontsize=tick_size)\n",
    "    plt.ylabel('Coefficient Values', fontsize=label_size)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the census income data\n",
    "\n",
    "The dataset, \"[US Adult Income](https://www.kaggle.com/johnolafenwa/us-census-data),\" was obtained from [Kaggle](https://www.kaggle.com) on 11/09/2017. It was downloaded as a zipped folder and the `adult-training.csv` and `adult-test.csv` files were extracted.\n",
    "\n",
    "- [CC0 1.0](https://creativecommons.org/publicdomain/zero/1.0/)\n",
    "\n",
    "A header is manually specified and the dataset is read into two pandas DataFrames below; one for the training set and one for the test set. The two are then combined. When reading in the data, all question marks are replaced with null values (missing data). We print the shape of the datasets to ensure that they are combined correctly and the dimensions are what we expect them to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of adult-training csv: (32561, 15)\n",
      "Shape of adult-test.csv: (16281, 15)\n",
      "Shape of combined csv data: (48842, 15)\n"
     ]
    }
   ],
   "source": [
    "# create header row as neither csv has a header\n",
    "header = ['age',\n",
    "          'type_employer',\n",
    "          'fnlwgt',\n",
    "          'education',\n",
    "          'education_num',\n",
    "          'marital',\n",
    "          'occupation',\n",
    "          'relationship',\n",
    "          'race',\n",
    "          'sex',\n",
    "          'capital_gain',\n",
    "          'capital_loss',\n",
    "          'hr_per_week',\n",
    "          'country',\n",
    "          'income']\n",
    "\n",
    "# read in the data from the two csv files\n",
    "df_train = pd.read_csv('../data_raw/adult-training.csv', names=header, na_values=[' ?'])\n",
    "df_test = pd.read_csv('../data_raw/adult-test.csv', names=header, skiprows=1, na_values=[' ?'])\n",
    "\n",
    "# print the shape of the data\n",
    "print('Shape of adult-training csv: ' + str(df_train.shape))\n",
    "print('Shape of adult-test.csv: ' + str( df_test.shape))\n",
    "\n",
    "# combine the two DataFrames into one dataset\n",
    "df = df_train.append(df_test)\n",
    "\n",
    "# print the shape of the full dataset\n",
    "print('Shape of combined csv data: ' + str(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "Based on the EDA above, investigate more in depth regarding the features in the dataset. Check for duplicates, missing values (\"should\" all be assigned already), and data that does not appear correct. For the purposes of this analysis we will not use the `fnlwgt` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop 'fnlwgt'\n",
    "df = df.drop('fnlwgt', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many rows contain missing data and which features are missing data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with missing data: 3620\n",
      "Rows without missing data: 45222\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_employer</th>\n",
       "      <td>2799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr_per_week</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               missing_count\n",
       "age                        0\n",
       "type_employer           2799\n",
       "education                  0\n",
       "education_num              0\n",
       "marital                    0\n",
       "occupation              2809\n",
       "relationship               0\n",
       "race                       0\n",
       "sex                        0\n",
       "capital_gain               0\n",
       "capital_loss               0\n",
       "hr_per_week                0\n",
       "country                  857\n",
       "income                     0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print missing data information\n",
    "print('Rows with missing data: ' + str(df[df.isnull().any(axis=1)].shape[0]))\n",
    "print('Rows without missing data: ' + str(df[df.notnull().all(axis=1)].shape[0]))\n",
    "pd.DataFrame(df.isnull().sum(axis=0), columns=['missing_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill in missing data with string so that the LabelEncoder can encode it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill na values with string\n",
    "df = df.fillna('NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relationship between education and education_num\n",
    "Due to the direct relationship (1:1), we do not need to include both of these variables. One will be discarded later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>education_num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Preschool</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st-4th</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5th-6th</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7th-8th</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9th</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10th</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11th</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12th</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HS-grad</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Some-college</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assoc-voc</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Assoc-acdm</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bachelors</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Masters</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prof-school</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doctorate</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               education_num\n",
       "education                   \n",
       " Preschool                 1\n",
       " 1st-4th                   2\n",
       " 5th-6th                   3\n",
       " 7th-8th                   4\n",
       " 9th                       5\n",
       " 10th                      6\n",
       " 11th                      7\n",
       " 12th                      8\n",
       " HS-grad                   9\n",
       " Some-college             10\n",
       " Assoc-voc                11\n",
       " Assoc-acdm               12\n",
       " Bachelors                13\n",
       " Masters                  14\n",
       " Prof-school              15\n",
       " Doctorate                16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pivot to see relationship between 'education' and 'education_num' variables\n",
    "pd.pivot_table(df[['education', 'education_num']], index=['education']).sort_values('education_num')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of data's integrity from a technical standpoint\n",
    "\n",
    "__age__:  \n",
    "Self-explanatory; data okay.\n",
    "\n",
    "__type_employer__:  \n",
    "Self-explanatory; missing data. Possible solutions - remove rows associated with missing values, or remove feature from data.\n",
    "\n",
    "__education/education_num__:  \n",
    "What is the difference between `Assoc-voc` and `Assoc-acdm`?\n",
    "\n",
    "__marital__:  \n",
    "What is the difference between `Married-AF-spouse` and `Married-civ-spouse`? It turns out that one refers to armed forces and the other refers to civilian.\n",
    "\n",
    "__occupation__:  \n",
    "This list includes a VERY broad range of occupations and does not provide much detail. The list itself is self-explanatory. There is missing data with the possible solutions - remove rows associated with missing values, or remove feature from data.\n",
    "\n",
    "__relationship__:  \n",
    "Not quite sure what this variable represents.\n",
    "\n",
    "__race__:  \n",
    "Self-explanatory; data okay. This variable is EXTREMELY limiting and does not recognize several different races.\n",
    "\n",
    "__sex__:  \n",
    "Self-explanatory; data okay. This variable indicates sex at birth only.\n",
    "\n",
    "__capital_gain/capital_loss__:  \n",
    "Continuous numerical value. Self-explanatory; data okay.\n",
    "\n",
    "__hr_per_week__:  \n",
    "Continuous numerical value. Self-explanatory; data okay.\n",
    "\n",
    "__country__:  \n",
    "The `country` variable appears to do a poor job describing country of origin. For example, what is \"South?\"\n",
    "\n",
    "__income__:  \n",
    "This variable should be binary and has multiple values that mean the same thing. The \".\" needs to be stripped from the end of two possible occurrences in the data to make it uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fix encoding for `income` response variable (should be binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' >50K'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fix dupicate results for 'income' variable\n",
    "df['income'] = df['income'].str.replace('.', '')\n",
    "df['income'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis - EDA\n",
    "\n",
    "At a high level explore the data. Find categorical variables, numerical variables, and determine how many possible values there are for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_count</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variable</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>74</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type_employer</th>\n",
       "      <td>9</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <td>16</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <td>16</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <td>7</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <td>15</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <td>6</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <td>5</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_gain</th>\n",
       "      <td>123</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capital_loss</th>\n",
       "      <td>99</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hr_per_week</th>\n",
       "      <td>96</td>\n",
       "      <td>int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>42</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>2</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              unique_count   dtype\n",
       "variable                          \n",
       "age                     74   int64\n",
       "type_employer            9  object\n",
       "education               16  object\n",
       "education_num           16   int64\n",
       "marital                  7  object\n",
       "occupation              15  object\n",
       "relationship             6  object\n",
       "race                     5  object\n",
       "sex                      2  object\n",
       "capital_gain           123   int64\n",
       "capital_loss            99   int64\n",
       "hr_per_week             96   int64\n",
       "country                 42  object\n",
       "income                   2  object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create DataFrame for nice presentation\n",
    "summary = pd.DataFrame(columns=['variable', 'unique_count', 'dtype'])\n",
    "\n",
    "# loop through features and append summary statistics to the DataFrame\n",
    "for i in df.columns:\n",
    "    summary = summary.append(pd.DataFrame({'variable': [i],\n",
    "                                           'unique_count': [str(len(df[i].unique()))],\n",
    "                                           'dtype': [str(df[i].dtype)]}))\n",
    "\n",
    "# print DataFrame\n",
    "summary.set_index('variable')[['unique_count', 'dtype']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at the summary statistics associated with the numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education_num</th>\n",
       "      <th>capital_gain</th>\n",
       "      <th>capital_loss</th>\n",
       "      <th>hr_per_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>48842.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "      <td>4035.000000</td>\n",
       "      <td>2282.000000</td>\n",
       "      <td>48842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.643585</td>\n",
       "      <td>10.078089</td>\n",
       "      <td>13061.665675</td>\n",
       "      <td>1872.825592</td>\n",
       "      <td>40.422382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>13.710510</td>\n",
       "      <td>2.570973</td>\n",
       "      <td>22711.237412</td>\n",
       "      <td>364.048529</td>\n",
       "      <td>12.391444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>3411.000000</td>\n",
       "      <td>1672.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7298.000000</td>\n",
       "      <td>1887.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>13550.000000</td>\n",
       "      <td>1977.000000</td>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>90.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>99999.000000</td>\n",
       "      <td>4356.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age  education_num  capital_gain  capital_loss   hr_per_week\n",
       "count  48842.000000   48842.000000   4035.000000   2282.000000  48842.000000\n",
       "mean      38.643585      10.078089  13061.665675   1872.825592     40.422382\n",
       "std       13.710510       2.570973  22711.237412    364.048529     12.391444\n",
       "min       17.000000       1.000000    114.000000    155.000000      1.000000\n",
       "25%       28.000000       9.000000   3411.000000   1672.000000     40.000000\n",
       "50%       37.000000      10.000000   7298.000000   1887.000000     40.000000\n",
       "75%       48.000000      12.000000  13550.000000   1977.000000     45.000000\n",
       "max       90.000000      16.000000  99999.000000   4356.000000     99.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# high-level summary statistics for numerical values\n",
    "df.replace(0, np.NaN).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summarize the categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_num</th>\n",
       "      <th>education</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>Preschool</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>1st-4th</th>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>5th-6th</th>\n",
       "      <td>509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>7th-8th</th>\n",
       "      <td>955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>9th</th>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>10th</th>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>11th</th>\n",
       "      <td>1812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>12th</th>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>HS-grad</th>\n",
       "      <td>15784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>Some-college</th>\n",
       "      <td>10878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>Assoc-voc</th>\n",
       "      <td>2061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>Assoc-acdm</th>\n",
       "      <td>1601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>Bachelors</th>\n",
       "      <td>8025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>Masters</th>\n",
       "      <td>2657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>Prof-school</th>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>Doctorate</th>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               age\n",
       "education_num education           \n",
       "1              Preschool        83\n",
       "2              1st-4th         247\n",
       "3              5th-6th         509\n",
       "4              7th-8th         955\n",
       "5              9th             756\n",
       "6              10th           1389\n",
       "7              11th           1812\n",
       "8              12th            657\n",
       "9              HS-grad       15784\n",
       "10             Some-college  10878\n",
       "11             Assoc-voc      2061\n",
       "12             Assoc-acdm     1601\n",
       "13             Bachelors      8025\n",
       "14             Masters        2657\n",
       "15             Prof-school     834\n",
       "16             Doctorate       594"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.groupby(['education_num', 'education'])['age'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop `education` feature as mentioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop duplicate dolumn\n",
    "df = df.drop('education', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Divorced</th>\n",
       "      <td>6633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married-AF-spouse</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married-civ-spouse</th>\n",
       "      <td>22379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Married-spouse-absent</th>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Never-married</th>\n",
       "      <td>16117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Separated</th>\n",
       "      <td>1530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Widowed</th>\n",
       "      <td>1518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          age\n",
       "marital                      \n",
       " Divorced                6633\n",
       " Married-AF-spouse         37\n",
       " Married-civ-spouse     22379\n",
       " Married-spouse-absent    628\n",
       " Never-married          16117\n",
       " Separated               1530\n",
       " Widowed                 1518"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.groupby(['marital'])['age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>occupation</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adm-clerical</th>\n",
       "      <td>5611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Armed-Forces</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Craft-repair</th>\n",
       "      <td>6112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Exec-managerial</th>\n",
       "      <td>6086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Farming-fishing</th>\n",
       "      <td>1490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Handlers-cleaners</th>\n",
       "      <td>2072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Machine-op-inspct</th>\n",
       "      <td>3022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other-service</th>\n",
       "      <td>4923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Priv-house-serv</th>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prof-specialty</th>\n",
       "      <td>6172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Protective-serv</th>\n",
       "      <td>983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sales</th>\n",
       "      <td>5504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tech-support</th>\n",
       "      <td>1446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transport-moving</th>\n",
       "      <td>2355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>2809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     age\n",
       "occupation              \n",
       " Adm-clerical       5611\n",
       " Armed-Forces         15\n",
       " Craft-repair       6112\n",
       " Exec-managerial    6086\n",
       " Farming-fishing    1490\n",
       " Handlers-cleaners  2072\n",
       " Machine-op-inspct  3022\n",
       " Other-service      4923\n",
       " Priv-house-serv     242\n",
       " Prof-specialty     6172\n",
       " Protective-serv     983\n",
       " Sales              5504\n",
       " Tech-support       1446\n",
       " Transport-moving   2355\n",
       "NaN                 2809"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.groupby(['occupation'])['age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relationship</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Husband</th>\n",
       "      <td>19716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Not-in-family</th>\n",
       "      <td>12583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other-relative</th>\n",
       "      <td>1506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Own-child</th>\n",
       "      <td>7581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unmarried</th>\n",
       "      <td>5125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wife</th>\n",
       "      <td>2331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   age\n",
       "relationship          \n",
       " Husband         19716\n",
       " Not-in-family   12583\n",
       " Other-relative   1506\n",
       " Own-child        7581\n",
       " Unmarried        5125\n",
       " Wife             2331"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.groupby(['relationship'])['age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amer-Indian-Eskimo</th>\n",
       "      <td>470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Asian-Pac-Islander</th>\n",
       "      <td>1519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>4685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Other</th>\n",
       "      <td>406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>41762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       age\n",
       "race                      \n",
       " Amer-Indian-Eskimo    470\n",
       " Asian-Pac-Islander   1519\n",
       " Black                4685\n",
       " Other                 406\n",
       " White               41762"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.groupby(['race'])['age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Female</th>\n",
       "      <td>16192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Male</th>\n",
       "      <td>32650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age\n",
       "sex           \n",
       " Female  16192\n",
       " Male    32650"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.groupby(['sex'])['age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cambodia</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>China</th>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Columbia</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cuba</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dominican-Republic</th>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ecuador</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>El-Salvador</th>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>England</th>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>France</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Germany</th>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Greece</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Guatemala</th>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Haiti</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Holand-Netherlands</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Honduras</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hong</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hungary</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iran</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ireland</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jamaica</th>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japan</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Laos</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mexico</th>\n",
       "      <td>951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nicaragua</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlying-US(Guam-USVI-etc)</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Peru</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Philippines</th>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poland</th>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Portugal</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Puerto-Rico</th>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scotland</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>South</th>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Taiwan</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Thailand</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trinadad&amp;Tobago</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United-States</th>\n",
       "      <td>43832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vietnam</th>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yugoslavia</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               age\n",
       "country                           \n",
       " Cambodia                       28\n",
       " Canada                        182\n",
       " China                         122\n",
       " Columbia                       85\n",
       " Cuba                          138\n",
       " Dominican-Republic            103\n",
       " Ecuador                        45\n",
       " El-Salvador                   155\n",
       " England                       127\n",
       " France                         38\n",
       " Germany                       206\n",
       " Greece                         49\n",
       " Guatemala                      88\n",
       " Haiti                          75\n",
       " Holand-Netherlands              1\n",
       " Honduras                       20\n",
       " Hong                           30\n",
       " Hungary                        19\n",
       " India                         151\n",
       " Iran                           59\n",
       " Ireland                        37\n",
       " Italy                         105\n",
       " Jamaica                       106\n",
       " Japan                          92\n",
       " Laos                           23\n",
       " Mexico                        951\n",
       " Nicaragua                      49\n",
       " Outlying-US(Guam-USVI-etc)     23\n",
       " Peru                           46\n",
       " Philippines                   295\n",
       " Poland                         87\n",
       " Portugal                       67\n",
       " Puerto-Rico                   184\n",
       " Scotland                       21\n",
       " South                         115\n",
       " Taiwan                         65\n",
       " Thailand                       30\n",
       " Trinadad&Tobago                27\n",
       " United-States               43832\n",
       " Vietnam                        86\n",
       " Yugoslavia                     23\n",
       "NaN                            857"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.groupby(['country'])['age'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>&lt;=50K</th>\n",
       "      <td>37155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>&gt;50K</th>\n",
       "      <td>11687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          age\n",
       "income       \n",
       " <=50K  37155\n",
       " >50K   11687"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.groupby(['income'])['age'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deal with missing values and encode categorical features\n",
    "\n",
    "1. Delete all rows associated with missing values reducing the total number of rows from 48,842 to 45,222 and naively encode categorical features.\n",
    "2. Delete features associated with missing values reducing the feature space from 14 to 11 and naively encode categorical features.\n",
    "3. Encode missing values as a category (not advised). This does not remove any features or rows.\n",
    "4. Binarize the categorical features (expand feature space significantly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## method 1\n",
    "# drop rows with missing data\n",
    "df_m1 = df[((df['type_employer'] != 'NaN') &\n",
    "            (df['occupation'] != 'NaN') &\n",
    "            (df['country'] != 'NaN'))].reset_index(drop=True)\n",
    "df_m1 = encode_cat_vars(df_m1)\n",
    "df_m1.to_csv('../data_clean/method1.csv', index=False)\n",
    "\n",
    "## method 2\n",
    "# drop features with missing data\n",
    "df_m2 = df.drop(['type_employer', 'occupation', 'country'], axis=1).reset_index(drop=True)\n",
    "df_m2 = encode_cat_vars(df_m2)\n",
    "df_m2.to_csv('../data_clean/method2.csv', index=False)\n",
    "\n",
    "## method 3\n",
    "# copy DataFrame to new variable and encode categorical variables\n",
    "df_m3 = df.copy()\n",
    "df_m3 = encode_cat_vars(df_m3)\n",
    "df_m3.to_csv('../data_clean/method3.csv', index=False)\n",
    "\n",
    "## method 4\n",
    "# copy DataFrame to new variable\n",
    "df_m4 = df.copy()\n",
    "df_m4 = binarize_cat_vars(df_m4)\n",
    "df_m4 = df_m4.drop(['type_employer_NaN', 'occupation_NaN', 'country_NaN'], axis=1)\n",
    "df_m4.to_csv('../data_clean/method4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split DataFrame into training and testing\n",
    "\n",
    "This split is done so that we do not perform any training on the true test set. We will split the training set later into a training/validation set that will be used to train and test the model(s). Once a model has been tuned it will be tested against the holdout test set we create below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly split 25% for a test set\n",
    "df_m1_test = df_m1.sample(frac=1/4, random_state=6)\n",
    "df_m2_test = df_m2.sample(frac=1/4, random_state=6)\n",
    "df_m3_test = df_m3.sample(frac=1/4, random_state=6)\n",
    "df_m4_test = df_m4.sample(frac=1/4, random_state=6)\n",
    "\n",
    "# keep the remaining 75% for a training set\n",
    "df_m1_train = df_m1.drop(df_m1_test.index.values)\n",
    "df_m2_train = df_m2.drop(df_m2_test.index.values)\n",
    "df_m3_train = df_m3.drop(df_m3_test.index.values)\n",
    "df_m4_train = df_m4.drop(df_m4_test.index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into features/response, training/validation, and standardize/scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the data for modeling\n",
    "x_train_m1, x_valid_m1, y_train_m1, y_valid_m1 = data_prep(df_m1_train)\n",
    "x_train_m2, x_valid_m2, y_train_m2, y_valid_m2 = data_prep(df_m2_train)\n",
    "x_train_m3, x_valid_m3, y_train_m3, y_valid_m3 = data_prep(df_m3_train)\n",
    "x_train_m4, x_valid_m4, y_train_m4, y_valid_m4 = data_prep(df_m4_train)\n",
    "\n",
    "# standardize and scale the test set as well (no split)\n",
    "x_test_m1, x_null_m1, y_test_m1, y_null_m1 = data_prep(df_m1_test)\n",
    "x_test_m2, x_null_m2, y_test_m2, y_null_m2 = data_prep(df_m2_test)\n",
    "x_test_m3, x_null_m3, y_test_m3, y_null_m3 = data_prep(df_m3_test)\n",
    "x_test_m4, x_null_m4, y_test_m4, y_null_m4 = data_prep(df_m4_test)\n",
    "\n",
    "# combine the splits back (just utilized the function to standardize and scale)\n",
    "x_test_m1 = np.vstack((x_test_m1, x_null_m1))\n",
    "y_test_m1 = np.append(y_test_m1, y_null_m1)\n",
    "x_test_m2 = np.vstack((x_test_m2, x_null_m2))\n",
    "y_test_m2 = np.append(y_test_m2, y_null_m2)\n",
    "x_test_m3 = np.vstack((x_test_m3, x_null_m3))\n",
    "y_test_m3 = np.append(y_test_m3, y_null_m3)\n",
    "x_test_m4 = np.vstack((x_test_m4, x_null_m4))\n",
    "y_test_m4 = np.append(y_test_m4, y_null_m4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Findings\n",
    "[[back to Contents](#Contents)]\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Pearson correlation confusion matrix among features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_heatmap(df_m1, title_prefix='Method 1: ')\n",
    "plt.savefig('../analysis/m1_pearson_corr_heatmap.png')\n",
    "corr_heatmap(df_m1, title_prefix='Filtered Method 1: ', threshold=0.2)\n",
    "plt.savefig('../analysis/m1_pearson_corr_heatmap_filtered.png')\n",
    "corr_heatmap(df_m2, title_prefix='Method 2: ')\n",
    "corr_heatmap(df_m3, title_prefix='Method 3: ')\n",
    "corr_heatmap(df_m4, title_prefix='Method 4: ', figsize=(16, 12), annot=False, cbar=True, tick_size=10)\n",
    "plt.savefig('../analysis/m4_pearson_corr_heatmap.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit logistic regression model with cross-validation and calculate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Method 1:')\n",
    "model1 = model_logistic(x_train_m1, x_valid_m1, x_test_m1, y_train_m1, y_valid_m1, y_test_m1)\n",
    "print('\\nMethod 2:')\n",
    "model2 = model_logistic(x_train_m2, x_valid_m2, x_test_m2, y_train_m2, y_valid_m2, y_test_m2)\n",
    "print('\\nMethod 3:')\n",
    "model3 = model_logistic(x_train_m3, x_valid_m3, x_test_m3, y_train_m3, y_valid_m3, y_test_m3)\n",
    "print('\\nMethod 4:')\n",
    "model4 = model_logistic(x_train_m4, x_valid_m4, x_test_m4, y_train_m4, y_valid_m4, y_test_m4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "visualize_coefs(model1, df_m1, title_prefix='Model 1: ')\n",
    "plt.savefig('../analysis/m1_coefficient_values_bargraph.png')\n",
    "visualize_coefs(model2, df_m2, title_prefix='Model 2: ')\n",
    "visualize_coefs(model3, df_m3, title_prefix='Model 3: ')\n",
    "visualize_coefs(model4, df_m4, title_prefix='Model 4: ', tick_size=10)\n",
    "plt.savefig('../analysis/m4_coefficient_values_bargraph.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion/Implications\n",
    "[[back to Contents](#Contents)]\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion<a id='blah'></a>\n",
    "[[back to Contents](#Contents)]\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[[back to Contents](#Contents)]\n",
    "\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
